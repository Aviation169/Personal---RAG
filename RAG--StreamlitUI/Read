# Upload your own personal file for analysis
if you don’t have a GPU laptop to run the Llama3.2 model locally, then I suggest you use Ollamas’ Llama 3.2, which doesn’t require a GPU laptop
